<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Trình xem bài giảng Trí tuệ nhân tạo</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .content-prose {
            max-width: 80ch;
        }
        .sidebar-link.active {
            background-color: #e5e7eb; /* gray-200 */
            color: #111827; /* gray-900 */
            font-weight: 600;
        }
        .lecture-content h3 {
            font-size: 1.5em;
            font-weight: 600;
            margin-top: 1.5em;
            margin-bottom: 0.5em;
            border-bottom: 1px solid #ddd;
            padding-bottom: 0.3em;
        }
        .lecture-content p {
            margin-bottom: 1em;
            line-height: 1.6;
        }
        .lecture-content ul {
            list-style-type: disc;
            padding-left: 2em;
            margin-bottom: 1em;
        }
        .lecture-content li {
            margin-bottom: 0.5em;
        }
        .lecture-content pre {
            background-color: #f4f4f4;
            padding: 1em;
            border-radius: 8px;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
    </style>
</head>
<body class="bg-gray-100 text-gray-800">

    <div class="flex h-screen">
        <!-- Sidebar for navigation -->
        <aside id="sidebar" class="w-72 bg-white p-4 space-y-2 transform -translate-x-full md:translate-x-0 transition-transform duration-300 ease-in-out fixed md:relative z-20 h-full overflow-y-auto shadow-lg">
            <h1 class="text-xl font-bold text-gray-900 mb-4">Mục lục</h1>
            <nav>
                <ul class="space-y-1">
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-1">Bài 1: Giới thiệu</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-2">Bài 2: Tác tử</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-3">Bài 3: Tìm kiếm</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-4">Bài 4: Tìm kiếm không thông tin</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-5">Bài 5: Tìm kiếm có thông tin</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-6">Bài 6: Tìm kiếm cục bộ</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-7">Bài 7: Bài toán CSP</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-8">Bài 8: Logic mệnh đề</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-10">Bài 10: Tổng quan về Học máy</a></li>
                    <li><a href="#" class="sidebar-link block px-4 py-2 rounded-lg text-gray-700 hover:bg-gray-200" data-target="lecture-11">Bài 11: Mạng Nơ-ron</a></li>
                </ul>
            </nav>
        </aside>

        <!-- Main content -->
        <main class="flex-1 p-4 md:p-8 overflow-y-auto">
            <!-- Mobile menu button -->
            <button id="menu-button" class="md:hidden fixed top-4 left-4 z-30 bg-white p-2 rounded-md shadow-md">
                <svg xmlns="http://www.w3.org/2000/svg" class="h-6 w-6" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7" />
                </svg>
            </button>
            
            <div id="content-container" class="bg-white p-6 md:p-8 rounded-xl shadow-md content-prose mx-auto">
                <!-- Lecture 1 -->
                <div id="lecture-1" class="lecture-content">
                    <h2 class="text-2xl font-bold mb-4">Bài 1: Giới thiệu Trí tuệ nhân tạo</h2>
                    <h3>Nội dung</h3>
                    <ul>
                        <li>Các định nghĩa về trí tuệ nhân tạo</li>
                        <li>Các khoa học cơ bản của trí tuệ nhân tạo</li>
                        <li>Lịch sử phát triển</li>
                        <li>Các ứng dụng của trí tuệ nhân tạo</li>
                    </ul>
                    <h3>Các định nghĩa</h3>
                    <p>Có 4 cách tiếp cận chính để định nghĩa Trí tuệ Nhân tạo:</p>
                    <ul>
                        <li><strong>Suy nghĩ như con người (Thinking Humanly):</strong> Nỗ lực làm cho máy tính có thể "suy nghĩ" như con người, tạo ra những cỗ máy có tâm trí theo đúng nghĩa đen.</li>
                        <li><strong>Hành động như con người (Acting Humanly):</strong> Tạo ra những cỗ máy có thể thực hiện các chức năng đòi hỏi trí thông minh khi được thực hiện bởi con người. Phép thử Turing là một ví dụ điển hình cho cách tiếp cận này.</li>
                        <li><strong>Suy nghĩ hợp lý (Thinking Rationally):</strong> Nghiên cứu các tính toán giúp máy tính có thể nhận thức, suy luận và hành động. Cách tiếp cận này dựa trên các "luật suy nghĩ" của logic.</li>
                        <li><strong>Hành động hợp lý (Acting Rationally):</strong> Thiết kế các "tác tử thông minh" (intelligent agents) có thể hành động để đạt được kết quả tốt nhất. Đây là hướng tiếp cận phổ biến và tổng quát nhất trong AI hiện đại.</li>
                    </ul>
                    <h3>Lịch sử phát triển</h3>
                    <ul>
                        <li><strong>1943-1955 (Giai đoạn thai nghén):</strong> Ra đời các ý tưởng đầu tiên về mạng nơ-ron nhân tạo (McCulloch và Pitts, 1943) và các khái niệm nền tảng như học máy, thuật toán di truyền (Alan Turing, 1950).</li>
                        <li><strong>1956 (Ra đời của AI):</strong> Hội thảo Dartmouth, nơi thuật ngữ "Artificial Intelligence" được chính thức đề xuất.</li>
                        <li><strong>1952-1969 (Kỳ vọng lớn):</strong> Phát triển các chương trình chứng minh định lý, chơi cờ và ngôn ngữ lập trình Lisp.</li>
                        <li><strong>1966–1973 (Giai đoạn khó khăn):</strong> Các bài toán thực tế tỏ ra phức tạp hơn nhiều so với dự đoán, dẫn đến sự cắt giảm tài trợ.</li>
                        <li><strong>1969-nay (Hệ thống dựa trên tri thức và sự bùng nổ):</strong> Sự phát triển của các hệ chuyên gia, sự trở lại của mạng nơ-ron, và gần đây là sự bùng nổ của học sâu và xử lý dữ liệu lớn.</li>
                    </ul>
                     <h3>Các ứng dụng</h3>
                    <p>AI có mặt trong hầu hết mọi lĩnh vực của cuộc sống:</p>
                    <ul>
                        <li><strong>Phần mềm:</strong> Các hệ thống tự thích nghi, giao diện thông minh, công cụ tìm kiếm, nhận dạng giọng nói.</li>
                        <li><strong>Y học:</strong> Chẩn đoán bệnh, giám sát bệnh nhân, phẫu thuật bằng robot.</li>
                        <li><strong>Giao thông:</strong> Xe tự lái (Google, Tesla), phát hiện người đi bộ, tối ưu hóa tuyến đường.</li>
                        <li><strong>Robot:</strong> Robot hút bụi, robot hình người (ASIMO), robot thăm dò không gian.</li>
                        <li><strong>Xử lý ngôn ngữ tự nhiên:</strong> Dịch máy, phân tích văn bản, phát hiện email rác.</li>
                        <li><strong>Trò chơi:</strong> Máy tính chơi cờ (Deep Blue), chơi bài.</li>
                    </ul>
                </div>

                <!-- Lecture 2 -->
                <div id="lecture-2" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 2: Tác tử (Agents)</h2>
                    <h3>Tác tử và Môi trường</h3>
                    <p><strong>Tác tử (Agent)</strong> là bất cứ thứ gì có thể xem là nhận thức môi trường của nó thông qua các <strong>bộ phận cảm nhận (sensors)</strong> và hành động lên môi trường đó thông qua các <strong>bộ phận hành động (actuators)</strong>.</p>
                    <ul>
                        <li><strong>Tác tử con người:</strong> Cảm biến là mắt, tai, mũi,...; cơ cấu chấp hành là tay, chân, miệng,...</li>
                        <li><strong>Tác tử robot:</strong> Cảm biến là camera, hồng ngoại,...; cơ cấu chấp hành là động cơ, bánh xe,...</li>
                    </ul>
                    <p>Hành vi của một tác tử được mô tả bởi <strong>hàm tác tử (agent function)</strong>, là một ánh xạ từ chuỗi nhận thức đến một hành động.</p>
                    <h3>Tác tử hợp lý (Rational Agent)</h3>
                    <p>Một tác tử hợp lý là tác tử hành động để <strong>tối đa hóa thước đo hiệu suất (performance measure)</strong> của nó, dựa trên bằng chứng được cung cấp bởi chuỗi nhận thức và bất kỳ kiến thức tích hợp sẵn nào mà tác tử có.</p>
                    <p>Sự hợp lý phụ thuộc vào 4 yếu tố (PEAS):</p>
                    <ul>
                        <li><strong>P</strong>erformance measure (Thước đo hiệu suất): Tiêu chí đánh giá thành công.</li>
                        <li><strong>E</strong>nvironment (Môi trường): Nơi tác tử hoạt động.</li>
                        <li><strong>A</strong>ctuators (Bộ phận hành động): Cách tác tử tác động lên môi trường.</li>
                        <li><strong>S</strong>ensors (Bộ phận cảm nhận): Cách tác tử nhận thức môi trường.</li>
                    </ul>
                    <h3>Phân loại môi trường</h3>
                    <ul>
                        <li><strong>Quan sát được hoàn toàn (Fully observable) vs. Quan sát được một phần (Partially observable):</strong> Cảm biến có cung cấp toàn bộ trạng thái của môi trường không?</li>
                        <li><strong>Tất định (Deterministic) vs. Ngẫu nhiên (Stochastic):</strong> Trạng thái tiếp theo có hoàn toàn được quyết định bởi trạng thái hiện tại và hành động của tác tử không?</li>
                        <li><strong>Phân đoạn (Episodic) vs. Tuần tự (Sequential):</strong> Lựa chọn hành động ở mỗi giai đoạn có phụ thuộc vào các giai đoạn trước đó không?</li>
                        <li><strong>Tĩnh (Static) vs. Động (Dynamic):</strong> Môi trường có thay đổi trong khi tác tử đang suy nghĩ không?</li>
                        <li><strong>Rời rạc (Discrete) vs. Liên tục (Continuous):</strong> Số lượng nhận thức và hành động có hữu hạn không?</li>
                        <li><strong>Đơn tác tử (Single agent) vs. Đa tác tử (Multi-agent):</strong> Có tác tử nào khác trong môi trường không?</li>
                    </ul>
                    <h3>Kiến trúc của các tác tử</h3>
                    <ul>
                        <li><strong>Tác tử phản xạ đơn giản (Simple reflex agents):</strong> Hành động dựa trên luật điều kiện-hành động, chỉ dựa vào nhận thức hiện tại.</li>
                        <li><strong>Tác tử phản xạ dựa trên mô hình (Model-based reflex agents):</strong> Duy trì một trạng thái nội bộ để theo dõi thế giới, xử lý các môi trường quan sát được một phần.</li>
                        <li><strong>Tác tử dựa trên mục tiêu (Goal-based agents):</strong> Hành động để đạt được mục tiêu của mình. Tìm kiếm và lập kế hoạch là các lĩnh vực con của AI dành cho việc tìm kiếm các chuỗi hành động để đạt được mục tiêu.</li>
                        <li><strong>Tác tử dựa trên lợi ích (Utility-based agents):</strong> Cố gắng tối đa hóa lợi ích mong đợi của mình. Một hàm lợi ích sẽ ánh xạ một trạng thái (hoặc một chuỗi trạng thái) tới một con số thực để đo lường mức độ "hạnh phúc".</li>
                    </ul>
                </div>

                <!-- Lecture 3 -->
                <div id="lecture-3" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 3: Giải quyết bài toán bằng tìm kiếm</h2>
                    <h3>Tác tử giải quyết bài toán</h3>
                    <p>Tác tử giải quyết bài toán là một loại tác tử dựa trên mục tiêu. Chúng sử dụng một mô tả nguyên tử về trạng thái và hành động để lập kế hoạch cho tương lai, thường là thông qua quá trình tìm kiếm một chuỗi các hành động để đạt được mục tiêu.</p>
                    <h3>Định nghĩa bài toán</h3>
                    <p>Một bài toán tìm kiếm được định nghĩa hình thức bởi 5 thành phần:</p>
                    <ul>
                        <li><strong>Trạng thái ban đầu (Initial state):</strong> Trạng thái mà tác tử bắt đầu.</li>
                        <li><strong>Hành động (Actions):</strong> Tập hợp các hành động có thể thực hiện được ở một trạng thái cụ thể.</li>
                        <li><strong>Mô hình chuyển tiếp (Transition model):</strong> Mô tả kết quả của việc thực hiện một hành động ở một trạng thái. Thường được định nghĩa bởi một hàm <code>RESULT(s, a)</code>.</li>
                        <li><strong>Kiểm tra mục tiêu (Goal test):</strong> Xác định xem một trạng thái có phải là trạng thái mục tiêu hay không.</li>
                        <li><strong>Chi phí đường đi (Path cost):</strong> Gán một chi phí số cho mỗi đường đi.</li>
                    </ul>
                    <p>Một <strong>nghiệm</strong> là một đường đi từ trạng thái ban đầu đến trạng thái mục tiêu.</p>
                    <h3>Tìm kiếm nghiệm</h3>
                    <p>Quá trình tìm kiếm xây dựng một <strong>cây tìm kiếm (search tree)</strong> với trạng thái ban đầu là gốc. Các nút trong cây được <strong>mở rộng (expanding)</strong>, tức là tạo ra các nút con tương ứng với các trạng thái có thể đạt được từ nút đó.</p>
                    <p>Các thuật toán tìm kiếm dựa trên việc quản lý một tập các nút chưa được mở rộng, gọi là <strong>biên (frontier)</strong>. Chiến lược chọn nút tiếp theo từ biên để mở rộng sẽ quyết định loại thuật toán tìm kiếm.</p>
                    <p><strong>Cấu trúc dữ liệu của một nút tìm kiếm bao gồm:</strong></p>
                    <ul>
                        <li>Trạng thái (STATE)</li>
                        <li>Nút cha (PARENT)</li>
                        <li>Hành động (ACTION) đã dẫn đến nút này</li>
                        <li>Chi phí đường đi (PATH-COST) từ gốc đến nút này, ký hiệu là g(n).</li>
                    </ul>
                     <h3>Đánh giá hiệu quả thuật toán</h3>
                    <p>Các thuật toán tìm kiếm được đánh giá dựa trên các tiêu chí sau:</p>
                    <ul>
                        <li><strong>Tính hoàn chỉnh (Completeness):</strong> Thuật toán có luôn tìm thấy nghiệm nếu nó tồn tại không?</li>
                        <li><strong>Tính tối ưu (Optimality):</strong> Thuật toán có tìm thấy nghiệm có chi phí thấp nhất không?</li>
                        <li><strong>Độ phức tạp thời gian (Time complexity):</strong> Mất bao lâu để tìm thấy nghiệm?</li>
                        <li><strong>Độ phức tạp không gian (Space complexity):</strong> Cần bao nhiêu bộ nhớ để thực hiện tìm kiếm?</li>
                    </ul>
                    <p>Độ phức tạp thường được đo bằng các tham số: <strong>b</strong> (hệ số rẽ nhánh), <strong>d</strong> (độ sâu của nghiệm nông nhất), và <strong>m</strong> (độ sâu tối đa của không gian trạng thái).</p>
                </div>

                <!-- Lecture 4 -->
                <div id="lecture-4" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 4: Tìm kiếm không có thông tin bổ sung (Uninformed Search)</h2>
                    <p>Các chiến lược tìm kiếm không thông tin, hay còn gọi là tìm kiếm "mù", không sử dụng bất kỳ thông tin nào về bài toán ngoài định nghĩa của nó. Chúng chỉ khác nhau ở thứ tự mở rộng các nút.</p>
                    <h3>Tìm kiếm theo chiều rộng (Breadth-First Search - BFS)</h3>
                    <ul>
                        <li><strong>Chiến lược:</strong> Mở rộng nút nông nhất chưa được mở rộng trong cây tìm kiếm.</li>
                        <li><strong>Cài đặt:</strong> Biên (frontier) là một hàng đợi FIFO (First-In, First-Out).</li>
                        <li><strong>Hoàn chỉnh:</strong> Có (nếu b hữu hạn).</li>
                        <li><strong>Tối ưu:</strong> Có (nếu chi phí các bước là bằng nhau).</li>
                        <li><strong>Thời gian:</strong> O(b^d).</li>
                        <li><strong>Không gian:</strong> O(b^d).</li>
                    </ul>
                    <h3>Tìm kiếm với chi phí cực tiểu (Uniform-Cost Search - UCS)</h3>
                    <ul>
                        <li><strong>Chiến lược:</strong> Mở rộng nút n có chi phí đường đi g(n) thấp nhất.</li>
                        <li><strong>Cài đặt:</strong> Biên là một hàng đợi ưu tiên (priority queue) được sắp xếp theo g(n).</li>
                        <li><strong>Hoàn chỉnh:</strong> Có.</li>
                        <li><strong>Tối ưu:</strong> Có.</li>
                        <li><strong>Thời gian:</strong> O(b^(1+floor(C*/ε))), với C* là chi phí của nghiệm tối ưu và ε là chi phí bước nhỏ nhất.</li>
                        <li><strong>Không gian:</strong> Tương tự thời gian.</li>
                    </ul>
                    <h3>Tìm kiếm theo chiều sâu (Depth-First Search - DFS)</h3>
                    <ul>
                        <li><strong>Chiến lược:</strong> Mở rộng nút sâu nhất trong cây tìm kiếm.</li>
                        <li><strong>Cài đặt:</strong> Biên là một ngăn xếp LIFO (Last-In, First-Out).</li>
                        <li><strong>Hoàn chỉnh:</strong> Không (có thể bị kẹt trong các nhánh vô hạn).</li>
                        <li><strong>Tối ưu:</strong> Không.</li>
                        <li><strong>Thời gian:</strong> O(b^m).</li>
                        <li><strong>Không gian:</strong> O(bm) - đây là ưu điểm lớn nhất của DFS.</li>
                    </ul>
                    <h3>Các biến thể của DFS</h3>
                    <ul>
                        <li><strong>Tìm kiếm chiều sâu giới hạn (Depth-Limited Search - DLS):</strong> DFS với một giới hạn độ sâu l.</li>
                        <li><strong>Tìm kiếm lặp sâu dần (Iterative Deepening Search - IDS):</strong> Thực hiện DLS với giới hạn độ sâu tăng dần (l = 0, 1, 2,...). Kết hợp ưu điểm của BFS (hoàn chỉnh, tối ưu) và DFS (yêu cầu bộ nhớ thấp).</li>
                    </ul>
                    <h3>Tìm kiếm từ hai hướng (Bidirectional Search)</h3>
                    <p>Thực hiện hai tìm kiếm đồng thời: một từ trạng thái ban đầu và một từ trạng thái mục tiêu, hy vọng chúng sẽ gặp nhau ở giữa. Điều này có thể giảm đáng kể độ phức tạp thời gian và không gian xuống còn O(b^(d/2)).</p>
                </div>

                <!-- Lecture 5 -->
                <div id="lecture-5" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 5: Tìm kiếm có thông tin bổ sung (Informed Search)</h2>
                    <p>Các chiến lược tìm kiếm có thông tin (heuristic search) sử dụng kiến thức đặc thù của bài toán ngoài định nghĩa của nó. Chúng sử dụng một <strong>hàm heuristic</strong>, h(n), để ước tính chi phí từ nút n đến mục tiêu.</p>
                    <h3>Tìm kiếm tham lam tốt nhất đầu tiên (Greedy Best-First Search)</h3>
                    <ul>
                        <li><strong>Chiến lược:</strong> Mở rộng nút có vẻ gần mục tiêu nhất.</li>
                        <li><strong>Hàm đánh giá:</strong> f(n) = h(n).</li>
                        <li><strong>Hoàn chỉnh:</strong> Không (có thể bị kẹt trong vòng lặp).</li>
                        <li><strong>Tối ưu:</strong> Không.</li>
                        <li><strong>Thời gian:</strong> O(b^m) trong trường hợp xấu nhất.</li>
                        <li><strong>Không gian:</strong> O(b^m) trong trường hợp xấu nhất.</li>
                    </ul>
                    <h3>Thuật toán A*</h3>
                    <p>Thuật toán A* là thuật toán tìm kiếm tốt nhất đầu tiên hoàn chỉnh và tối ưu nhất được biết đến.</p>
                    <ul>
                        <li><strong>Chiến lược:</strong> Mở rộng nút có tổng chi phí đường đi đã qua và chi phí ước tính đến mục tiêu là nhỏ nhất.</li>
                        <li><strong>Hàm đánh giá:</strong> f(n) = g(n) + h(n).</li>
                        <li><strong>Tính chất quan trọng:</strong>
                            <ul>
                                <li><strong>Hàm heuristic chấp nhận được (Admissible):</strong> Nếu h(n) không bao giờ đánh giá quá cao chi phí thực tế để đến mục tiêu. A* sử dụng heuristic chấp nhận được là tối ưu.</li>
                                <li><strong>Hàm heuristic nhất quán (Consistent/Monotonic):</strong> Nếu với mọi nút n và mọi nút con n' của n, h(n) ≤ c(n, a, n') + h(n'). A* sử dụng heuristic nhất quán sẽ tìm thấy đường đi tối ưu đến bất kỳ nút nào được mở rộng.</li>
                            </ul>
                        </li>
                        <li><strong>Hoàn chỉnh:</strong> Có.</li>
                        <li><strong>Tối ưu:</strong> Có.</li>
                        <li><strong>Độ phức tạp:</strong> Phụ thuộc rất nhiều vào chất lượng của hàm heuristic.</li>
                    </ul>
                     <h3>Ảnh hưởng của hàm Heuristic</h3>
                    <p>Chất lượng của hàm heuristic rất quan trọng. Nếu ta có hai hàm heuristic chấp nhận được là h1 và h2, và h2(n) ≥ h1(n) với mọi n, thì h2 được gọi là <strong>chiếm ưu thế (dominates)</strong> so với h1. Sử dụng hàm heuristic chiếm ưu thế hơn sẽ giúp A* không bao giờ mở rộng nhiều nút hơn so với khi dùng hàm còn lại.</p>
                </div>

                <!-- Lecture 6 -->
                <div id="lecture-6" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 6: Tìm kiếm cục bộ (Local Search)</h2>
                    <p>Các thuật toán tìm kiếm cục bộ hoạt động trên một trạng thái đơn (thay vì nhiều đường đi) và cố gắng cải thiện nó. Chúng không quan tâm đến đường đi mà chỉ quan tâm đến trạng thái cuối cùng. Chúng hữu ích cho các bài toán tối ưu.</p>
                    <h3>Thuật toán leo đồi (Hill-Climbing Search)</h3>
                    <ul>
                        <li><strong>Chiến lược:</strong> Là một vòng lặp di chuyển liên tục theo hướng tăng giá trị (leo dốc). Nó dừng lại khi đạt đến một "đỉnh" nơi không có láng giềng nào có giá trị cao hơn.</li>
                        <li><strong>Nhược điểm:</strong> Dễ bị kẹt ở <strong>cực đại cục bộ (local maxima)</strong>, các "cao nguyên" (plateaus) hoặc các "sườn núi" (ridges).</li>
                        <li><strong>Biến thể:</strong> Leo đồi ngẫu nhiên (Stochastic hill climbing), Leo đồi lựa chọn đầu tiên (First-choice hill climbing), Leo đồi khởi tạo lại ngẫu nhiên (Random-restart hill climbing).</li>
                    </ul>
                    <h3>Thuật toán mô phỏng luyện kim (Simulated Annealing)</h3>
                    <ul>
                        <li><strong>Chiến lược:</strong> Kết hợp leo đồi với một bước di chuyển ngẫu nhiên để thoát khỏi các cực đại cục bộ. Nó luôn chấp nhận các bước đi tốt hơn, nhưng cũng chấp nhận các bước đi tệ hơn với một xác suất giảm dần theo "nhiệt độ" (temperature).</li>
                        <li><strong>Lịch trình nhiệt độ (Schedule):</strong> Cách nhiệt độ T giảm dần theo thời gian là rất quan trọng. Nếu T giảm đủ chậm, thuật toán sẽ tìm được cực đại toàn cục với xác suất tiến tới 1.</li>
                    </ul>
                     <h3>Tìm kiếm Beam cục bộ (Local Beam Search)</h3>
                    <ul>
                        <li><strong>Chiến lược:</strong> Giữ k trạng thái cùng một lúc thay vì chỉ một. Nó bắt đầu với k trạng thái được tạo ngẫu nhiên, sau đó tại mỗi bước, nó tạo ra tất cả các trạng thái kế thừa của cả k trạng thái. Nếu có trạng thái mục tiêu thì dừng, nếu không, nó chọn k trạng thái tốt nhất từ danh sách kế thừa và lặp lại.</li>
                    </ul>
                    <h3>Thuật toán di truyền (Genetic Algorithms - GA)</h3>
                    <p>GA là một biến thể của tìm kiếm ngẫu nhiên trong đó một "quần thể" các trạng thái (được gọi là "cá thể") được tiến hóa.</p>
                    <ul>
                        <li><strong>Cá thể:</strong> Thường được biểu diễn dưới dạng một chuỗi (ví dụ: chuỗi bit).</li>
                        <li><strong>Hàm thích nghi (Fitness function):</strong> Đánh giá chất lượng của mỗi trạng thái.</li>
                        <li><strong>Quá trình tiến hóa:</strong>
                            <ol>
                                <li><strong>Lựa chọn (Selection):</strong> Chọn các cặp cá thể để sinh sản. Các cá thể có độ thích nghi cao hơn có nhiều khả năng được chọn hơn.</li>
                                <li><strong>Lai ghép (Crossover):</strong> Tạo ra một hoặc nhiều con từ một cặp cha mẹ bằng cách kết hợp vật liệu di truyền của chúng.</li>
                                <li><strong>Đột biến (Mutation):</strong> Áp dụng các thay đổi ngẫu nhiên nhỏ cho các cá thể con.</li>
                            </ol>
                        </li>
                        <li><strong>Kết thúc:</strong> Thuật toán dừng lại khi một cá thể đủ tốt được tìm thấy, hoặc sau một số thế hệ nhất định.</li>
                    </ul>
                </div>

                <!-- Lecture 7 -->
                <div id="lecture-7" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 7: Bài toán Thỏa mãn Ràng buộc (CSP)</h2>
                    <h3>Định nghĩa CSP</h3>
                    <p>Bài toán thỏa mãn ràng buộc là một loại bài toán tìm kiếm đặc biệt, được định nghĩa bởi:</p>
                    <ul>
                        <li>Một tập các <strong>biến (variables)</strong> X = {X₁, ..., Xₙ}.</li>
                        <li>Một tập các <strong>miền giá trị (domains)</strong> D = {D₁, ..., Dₙ}, trong đó Dᵢ là tập các giá trị có thể có của biến Xᵢ.</li>
                        <li>Một tập các <strong>ràng buộc (constraints)</strong> C, mỗi ràng buộc xác định một tổ hợp giá trị hợp lệ cho một tập con các biến.</li>
                    </ul>
                    <p>Một <strong>nghiệm</strong> của CSP là một phép gán giá trị hoàn chỉnh và nhất quán cho tất cả các biến.</p>
                    <p><strong>Ví dụ:</strong> Bài toán tô màu bản đồ, bài toán 8 quân hậu, bài toán mật mã số học.</p>
                    <h3>Lan truyền ràng buộc (Constraint Propagation)</h3>
                    <p>Đây là một dạng suy luận giúp giảm miền giá trị hợp lệ của các biến, từ đó đơn giản hóa bài toán. Kỹ thuật phổ biến nhất là <strong>nhất quán cung (Arc Consistency)</strong>.</p>
                    <ul>
                        <li>Một cung (Xᵢ, Xⱼ) là nhất quán nếu với mọi giá trị x trong Dᵢ, tồn tại một giá trị y trong Dⱼ sao cho (x, y) là hợp lệ.</li>
                        <li>Thuật toán <strong>AC-3</strong> có thể được sử dụng để thực thi nhất quán cung cho toàn bộ CSP.</li>
                    </ul>
                     <h3>Tìm kiếm quay lui (Backtracking Search)</h3>
                    <p>Đây là thuật toán cơ bản để giải CSP, là một dạng tìm kiếm theo chiều sâu (DFS) có cải tiến:</p>
                    <ul>
                        <li>Chỉ xem xét các phép gán cho một biến tại một thời điểm.</li>
                        <li>Kiểm tra ràng buộc ngay khi gán và quay lui nếu không có giá trị hợp lệ.</li>
                    </ul>
                    <p>Hiệu quả của tìm kiếm quay lui có thể được cải thiện đáng kể bằng các heuristic:</p>
                    <ul>
                        <li><strong>Chọn biến (Variable Ordering):</strong>
                            <ul>
                                <li><strong>Giá trị còn lại tối thiểu (Minimum Remaining Values - MRV):</strong> Chọn biến có ít giá trị hợp lệ còn lại nhất.</li>
                                <li><strong>Bậc (Degree Heuristic):</strong> Chọn biến có nhiều ràng buộc nhất với các biến chưa được gán.</li>
                            </ul>
                        </li>
                        <li><strong>Chọn giá trị (Value Ordering):</strong>
                            <ul>
                                <li><strong>Giá trị ít ràng buộc nhất (Least Constraining Value):</strong> Chọn giá trị mà loại bỏ ít lựa chọn nhất cho các biến láng giềng.</li>
                            </ul>
                        </li>
                    </ul>
                     <h3>Tìm kiếm cục bộ cho CSP</h3>
                     <p>Các thuật toán tìm kiếm cục bộ, như thuật toán <strong>min-conflicts</strong>, có thể rất hiệu quả cho CSP. Thuật toán này bắt đầu với một phép gán hoàn chỉnh (có thể vi phạm ràng buộc) và cố gắng sửa chữa nó bằng cách thay đổi giá trị của một biến xung đột để giảm thiểu số lượng xung đột.</p>
                </div>

                <!-- Lecture 8 -->
                <div id="lecture-8" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 8: Tác tử Logic và Logic Mệnh đề</h2>
                    <h3>Tác tử dựa trên tri thức</h3>
                    <p>Tác tử dựa trên tri thức có một <strong>cơ sở tri thức (Knowledge Base - KB)</strong>, là một tập hợp các câu biểu diễn những gì nó biết về thế giới. Tác tử có thể suy luận các câu mới từ KB và sử dụng chúng để đưa ra quyết định.</p>
                    <h3>Logic</h3>
                    <p>Logic là một ngôn ngữ hình thức để biểu diễn thông tin sao cho có thể rút ra các kết luận. Một logic bao gồm:</p>
                    <ul>
                        <li><strong>Cú pháp (Syntax):</strong> Quy định cách xây dựng các câu hợp lệ.</li>
                        <li><strong>Ngữ nghĩa (Semantics):</strong> Xác định "ý nghĩa" của các câu; định nghĩa sự thật của mỗi câu đối với mỗi thế giới có thể (mô hình).</li>
                    </ul>
                    <p><strong>Sự kéo theo (Entailment):</strong> Một câu α được kéo theo bởi KB (ký hiệu KB ⊨ α) nếu α đúng trong tất cả các thế giới mà KB đúng.</p>
                    <p><strong>Suy diễn (Inference):</strong> Là quá trình rút ra các câu mới từ các câu cũ. Một thủ tục suy diễn được gọi là <strong>đúng đắn (sound)</strong> nếu nó chỉ rút ra các câu được kéo theo, và <strong>hoàn chỉnh (complete)</strong> nếu nó có thể rút ra mọi câu được kéo theo.</p>
                    <h3>Logic mệnh đề (Propositional Logic)</h3>
                    <p>Logic mệnh đề là một logic đơn giản bao gồm các ký hiệu mệnh đề (P, Q,...) và các toán tử logic (AND, OR, NOT, IMPLIES, IFF).</p>
                    <ul>
                        <li><strong>Câu nguyên tử (Atomic sentence):</strong> Một ký hiệu mệnh đề duy nhất.</li>
                        <li><strong>Câu phức hợp (Complex sentence):</strong> Được tạo thành từ các câu đơn giản hơn và các toán tử logic.</li>
                    </ul>
                     <h3>Chứng minh logic mệnh đề</h3>
                    <p>Có nhiều thuật toán để kiểm tra sự kéo theo trong logic mệnh đề:</p>
                    <ul>
                        <li><strong>Kiểm tra mô hình bằng bảng chân lý (Truth-table enumeration):</strong> Liệt kê tất cả các mô hình có thể có và kiểm tra xem α có đúng trong mọi mô hình mà KB đúng hay không. Đúng đắn và hoàn chỉnh, nhưng độ phức tạp là O(2ⁿ).</li>
                        <li><strong>Chứng minh bằng luật suy diễn:</strong> Áp dụng các luật suy diễn (như Modus Ponens, And-Elimination) để tạo ra một chuỗi các kết luận dẫn đến câu mong muốn.</li>
                        <li><strong>Thuật toán phân giải (Resolution):</strong> Một thủ tục suy diễn duy nhất, hoàn chỉnh cho logic mệnh đề. Nó hoạt động trên các câu ở Dạng Chuẩn Hội (CNF) và thường được sử dụng trong các hệ thống chứng minh định lý tự động.</li>
                        <li><strong>Suy diễn tiến và lùi (Forward and backward chaining):</strong> Các thuật toán suy diễn tuyến tính về thời gian cho các mệnh đề Horn (một tập con của logic mệnh đề).</li>
                    </ul>
                </div>

                <!-- Lecture 10 -->
                <div id="lecture-10" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 10: Tổng quan về Học máy (Machine Learning)</h2>
                    <h3>Định nghĩa</h3>
                    <p><strong>Học máy (Machine Learning - ML)</strong> là lĩnh vực nghiên cứu về các thuật toán và mô hình thống kê mà hệ thống máy tính sử dụng để thực hiện các nhiệm vụ mà không cần sử dụng các chỉ dẫn tường minh, thay vào đó dựa vào các mẫu và suy luận. Nói cách khác, ML là cách để máy tính học hỏi từ dữ liệu.</p>
                    <h3>Chu trình thiết kế hệ thống học máy</h3>
                    <ol>
                        <li><strong>Thu thập dữ liệu (Collect data):</strong> Bước đầu tiên và quan trọng nhất.</li>
                        <li><strong>Chọn đặc trưng (Choose features):</strong> Lựa chọn các thuộc tính quan trọng nhất từ dữ liệu để làm đầu vào cho mô hình.</li>
                        <li><strong>Chọn mô hình (Choose model):</strong> Lựa chọn loại mô hình phù hợp với bài toán (ví dụ: cây quyết định, mạng nơ-ron, máy vector hỗ trợ).</li>
                        <li><strong>Huấn luyện bộ phân lớp (Train classifier):</strong> Sử dụng dữ liệu huấn luyện để "dạy" mô hình. Quá trình này thường liên quan đến việc tối ưu hóa các tham số của mô hình.</li>
                        <li><strong>Đánh giá bộ phân lớp (Evaluate classifier):</strong> Sử dụng dữ liệu kiểm tra (chưa từng thấy trước đó) để đánh giá hiệu suất của mô hình.</li>
                    </ol>
                     <h3>Phân loại bài toán học máy</h3>
                    <p>Có ba loại chính của bài toán học máy:</p>
                    <ul>
                        <li>
                            <strong>Học có giám sát (Supervised Learning):</strong>
                            <ul>
                                <li><strong>Dữ liệu:</strong> Được gán nhãn với đầu ra chính xác.</li>
                                <li><strong>Mục tiêu:</strong> Học một hàm ánh xạ từ đầu vào đến đầu ra.</li>
                                <li><strong>Các loại bài toán:</strong>
                                    <ul>
                                        <li><strong>Phân loại (Classification):</strong> Đầu ra là một nhãn rời rạc (ví dụ: "chó" hoặc "mèo").</li>
                                        <li><strong>Hồi quy (Regression):</strong> Đầu ra là một giá trị liên tục (ví dụ: giá nhà).</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                        <li>
                            <strong>Học không giám sát (Unsupervised Learning):</strong>
                            <ul>
                                <li><strong>Dữ liệu:</strong> Không được gán nhãn.</li>
                                <li><strong>Mục tiêu:</strong> Tìm ra cấu trúc hoặc các mẫu ẩn trong dữ liệu.</li>
                                <li><strong>Các loại bài toán:</strong>
                                    <ul>
                                        <li><strong>Phân cụm (Clustering):</strong> Nhóm các điểm dữ liệu tương tự lại với nhau.</li>
                                        <li><strong>Giảm chiều dữ liệu (Dimensionality Reduction):</strong> Giảm số lượng các biến ngẫu nhiên đang được xem xét.</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                         <li>
                            <strong>Học củng cố (Reinforcement Learning):</strong>
                            <ul>
                                <li><strong>Mô hình:</strong> Một "tác tử" học cách hành động trong một "môi trường" để tối đa hóa một phần thưởng tích lũy.</li>
                                <li><strong>Quá trình học:</strong> Dựa trên thử và sai. Tác tử nhận được phần thưởng cho các hành động tốt và hình phạt cho các hành động xấu.</li>
                                <li><strong>Ứng dụng:</strong> Robot, chơi game, điều khiển tự động.</li>
                            </ul>
                        </li>
                    </ul>
                </div>

                <!-- Lecture 11 -->
                <div id="lecture-11" class="lecture-content hidden">
                    <h2 class="text-2xl font-bold mb-4">Bài 11: Mạng Nơ-ron (Neural Networks)</h2>
                     <h3>Mô hình Nơ-ron</h3>
                    <p>Một nơ-ron nhân tạo là một đơn vị tính toán lấy cảm hứng từ nơ-ron sinh học. Nó nhận một hoặc nhiều đầu vào, tính tổng có trọng số của chúng, cộng thêm một độ lệch (bias), và sau đó áp dụng một <strong>hàm kích hoạt (activation function)</strong> phi tuyến để tạo ra một đầu ra.</p>
                    <p>Các hàm kích hoạt phổ biến bao gồm: Hard Limit, Sigmoid (Log-Sigmoid, Tan-Sigmoid), và ReLU (Rectified Linear Unit).</p>
                    <h3>Kiến trúc mạng</h3>
                    <p>Các nơ-ron được tổ chức thành các <strong>tầng (layers)</strong>. Một mạng nơ-ron điển hình có:</p>
                    <ul>
                        <li><strong>Tầng vào (Input Layer):</strong> Nhận dữ liệu đầu vào.</li>
                        <li><strong>Các tầng ẩn (Hidden Layers):</strong> Một hoặc nhiều tầng nằm giữa tầng vào và tầng ra. Đây là nơi hầu hết các phép tính toán diễn ra.</li>
                        <li><strong>Tầng ra (Output Layer):</strong> Tạo ra kết quả cuối cùng.</li>
                    </ul>
                    <p>Các mạng được gọi là <strong>mạng truyền thẳng (feed-forward networks)</strong> nếu các kết nối không tạo thành chu trình.</p>
                    <h3>Mạng Perceptron</h3>
                    <p>Perceptron là dạng mạng nơ-ron đơn giản nhất, chỉ có một nơ-ron duy nhất (hoặc một tầng nơ-ron) với hàm kích hoạt bước (step function). Nó chỉ có thể học các bài toán <strong>phân loại tuyến tính (linearly separable)</strong>. Luật học Perceptron được sử dụng để cập nhật trọng số dựa trên lỗi phân loại.</p>
                    <h3>Mạng Perceptron đa tầng (Multilayer Perceptrons - MLP)</h3>
                    <p>MLP có một hoặc nhiều tầng ẩn, cho phép chúng học các hàm phi tuyến phức tạp và giải quyết các bài toán không thể phân loại tuyến tính (như bài toán XOR).</p>
                    <h3>Huấn luyện mạng nơ-ron: Lan truyền ngược (Backpropagation)</h3>
                    <p>Backpropagation là thuật toán phổ biến nhất để huấn luyện MLP. Đây là một thuật toán học có giám sát, hoạt động theo hai giai đoạn:</p>
                    <ol>
                        <li><strong>Lan truyền tiến (Forward Pass):</strong> Dữ liệu đầu vào được đưa qua mạng để tính toán đầu ra và sai số (loss) so với đầu ra thực tế.</li>
                        <li><strong>Lan truyền ngược (Backward Pass):</strong> Sai số được lan truyền ngược từ tầng ra về tầng vào. Gradient của hàm sai số theo từng trọng số được tính toán (sử dụng quy tắc chuỗi trong giải tích). Các trọng số sau đó được cập nhật theo hướng ngược lại của gradient để giảm thiểu sai số (sử dụng một thuật toán tối ưu như Gradient Descent).</li>
                    </ol>
                </div>
            </div>
        </main>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const links = document.querySelectorAll('.sidebar-link');
            const contentDivs = document.querySelectorAll('.lecture-content');
            const menuButton = document.getElementById('menu-button');
            const sidebar = document.getElementById('sidebar');

            function setActiveLink(targetId) {
                links.forEach(link => {
                    if (link.dataset.target === targetId) {
                        link.classList.add('active');
                    } else {
                        link.classList.remove('active');
                    }
                });
            }

            function showContent(targetId) {
                 contentDivs.forEach(div => {
                    div.classList.add('hidden');
                });
                const targetContent = document.getElementById(targetId);
                if (targetContent) {
                    targetContent.classList.remove('hidden');
                }
            }

            // Initial setup
            const firstLink = links[0];
            if (firstLink) {
                 const initialTarget = firstLink.dataset.target;
                 setActiveLink(initialTarget);
                 showContent(initialTarget);
            }


            links.forEach(link => {
                link.addEventListener('click', function(e) {
                    e.preventDefault();
                    const targetId = this.dataset.target;
                    
                    showContent(targetId);
                    setActiveLink(targetId);

                    // Hide sidebar on mobile after click
                    if (window.innerWidth < 768) {
                        sidebar.classList.add('-translate-x-full');
                    }
                });
            });

            // Toggle sidebar on mobile
            menuButton.addEventListener('click', function() {
                sidebar.classList.toggle('-translate-x-full');
            });
        });
    </script>
</body>
</html>
